# ESC-Net: SAR Image Colorizer

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ashiksharonm/esc-net-sar-image-colorizer/blob/main/sar_novel_v5_colorsar_protocol.ipynb)

A novel deep learning approach for colorizing Synthetic Aperture Radar (SAR) images using the **ColorSAR Protocol** with a custom **ResNet34 + CBAM** architecture.

## ğŸ¯ Overview

This project translates grayscale SAR images into colorized optical-style images by predicting the **ab** (chrominance) channels in the LAB color space. The approach follows the ColorSAR evaluation protocol, which uses the ground truth **L** (Lightness) channel during inference to ensure fair comparison with existing methods.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ESC-Net Architecture                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚   SAR Input (1ch)                                                   â”‚
â”‚        â”‚                                                            â”‚
â”‚        â–¼                                                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                   â”‚
â”‚   â”‚  Adapt Conv â”‚  7x7, stride 2, 1â†’64 channels                    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                   â”‚
â”‚        â”‚                                                            â”‚
â”‚        â–¼                                                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚              ResNet34 Encoder + CBAM                    â”‚       â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚       â”‚
â”‚   â”‚  â”‚Layer 1  â”‚â”€â”€â–¶â”‚Layer 2  â”‚â”€â”€â–¶â”‚Layer 3  â”‚â”€â”€â–¶â”‚Layer 4  â”‚ â”‚       â”‚
â”‚   â”‚  â”‚ 64ch    â”‚   â”‚ 128ch   â”‚   â”‚ 256ch   â”‚   â”‚ 512ch   â”‚ â”‚       â”‚
â”‚   â”‚  â”‚ +CBAM   â”‚   â”‚ +CBAM   â”‚   â”‚ +CBAM   â”‚   â”‚ +CBAM   â”‚ â”‚       â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚       â”‚
â”‚   â”‚       â”‚             â”‚             â”‚             â”‚       â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚           â”‚             â”‚             â”‚             â”‚               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚       â–¼             â–¼             â–¼             â–¼       â”‚       â”‚
â”‚   â”‚              U-Net Style Decoder                        â”‚       â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚       â”‚
â”‚   â”‚  â”‚  Up 1   â”‚â—€â”€â”€â”‚  Up 2   â”‚â—€â”€â”€â”‚  Up 3   â”‚â—€â”€â”€â”‚  Up 4   â”‚ â”‚       â”‚
â”‚   â”‚  â”‚ +Skip   â”‚   â”‚ +Skip   â”‚   â”‚ +Skip   â”‚   â”‚ 512â†’256 â”‚ â”‚       â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚           â”‚                                                         â”‚
â”‚           â–¼                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                   â”‚
â”‚   â”‚  Output Conv â”‚  1x1 Conv â†’ Tanh â†’ 2 channels (ab)              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                   â”‚
â”‚           â”‚                                                         â”‚
â”‚           â–¼                                                         â”‚
â”‚   ab Output (2ch)  â”€â”€â”€â”€â”€â”€â”                                          â”‚
â”‚                          â”‚                                          â”‚
â”‚   GT L Channel â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”œâ”€â”€â–¶ LAB â†’ RGB Conversion â†’ Colorized     â”‚
â”‚                          â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CBAM (Convolutional Block Attention Module)

CBAM is applied at each encoder level to help the model focus on structurally important features (roads, buildings) rather than speckle noise:

```
Input Feature Map
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Channel    â”‚  AdaptiveAvgPool â†’ FC â†’ ReLU â†’ FC â†’ Sigmoid
â”‚  Attention   â”‚  â†’ Element-wise multiply
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Spatial    â”‚  AvgPool + MaxPool â†’ Conv â†’ Sigmoid
â”‚  Attention   â”‚  â†’ Element-wise multiply
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
Refined Feature Map
```

## ğŸ“Š Dataset

| Property | Value |
|----------|-------|
| **Source** | Sentinel-1 (SAR) & Sentinel-2 (Optical) |
| **Total Patches** | 64,000 paired images |
| **Resolution** | 128 Ã— 128 pixels |
| **Format** | `.npz` (NumPy compressed) |
| **Train/Val Split** | 90% / 10% |

Each `.npz` file contains:
- `sar_denoised`: Denoised SAR image (grayscale)
- `rgb`: Corresponding optical RGB image

## ğŸ”§ Training Details

| Parameter | Value |
|-----------|-------|
| **Optimizer** | AdamW |
| **Learning Rate** | 1e-4 |
| **Batch Size** | 32 |
| **Loss Function** | MSE (Mean Squared Error) |
| **Color Space** | LAB (predict ab channels) |
| **Epochs** | 50 |
| **Hardware** | NVIDIA A100 GPU |

## ğŸ“ˆ Evaluation Protocol (ColorSAR)

We follow the **ColorSAR** evaluation protocol:
1. Model predicts **ab** channels from SAR input
2. **Ground Truth L** channel is used for reconstruction (not predicted L)
3. LAB â†’ RGB conversion for final output
4. Metrics: **PSNR** and **SSIM** calculated on RGB

This ensures fair comparison with published results (e.g., ColorSAR achieves ~0.94 SSIM using this protocol).

## ğŸš€ Quick Start

### Option 1: Google Colab (Recommended)
Click the "Open in Colab" badge above and run all cells.

### Option 2: Local Setup
```bash
# Clone the repository
git clone https://github.com/ashiksharonm/esc-net-sar-image-colorizer.git
cd esc-net-sar-image-colorizer

# Install dependencies
pip install torch torchvision matplotlib numpy tqdm scikit-image

# Run the notebook
jupyter notebook sar_novel_v5_colorsar_protocol.ipynb
```

## ğŸ“ Project Structure

```
esc-net-sar-image-colorizer/
â”œâ”€â”€ sar_novel_v5_colorsar_protocol.ipynb  # Main training notebook
â”œâ”€â”€ README.md                              # This file
â””â”€â”€ requirements.txt                       # Python dependencies
```

## ğŸ”¬ Key Contributions

1. **Novel CBAM Integration**: We apply CBAM attention at each encoder level to emphasize structural features over speckle noise
2. **ColorSAR Protocol Compliance**: Fair evaluation using ground truth Lightness channel
3. **Lightweight Architecture**: ResNet34 backbone (vs. heavier ResNet50+DenseNet ensembles in ColorSAR)

## ğŸ“š References

1. Schmitt, M., & Hughes, L. H. (2023). *Benchmarking Protocol for SAR Colorization*
2. Woo, S., et al. (2018). *CBAM: Convolutional Block Attention Module*
3. He, K., et al. (2016). *Deep Residual Learning for Image Recognition*

## ğŸ“„ License

This project is for academic research purposes.

## ğŸ‘¤ Author

**Ashik Sharon M**
- GitHub: [@ashiksharonm](https://github.com/ashiksharonm)
